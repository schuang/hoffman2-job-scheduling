<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" />

    
        <title>Hoffman2 Cluster Job Scheduling System - Hoffman2 Cluster Job Scheduling</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?digest=df49af52631e7917044a9c21a57f7b83170a6dd0" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.59c74d8c95b765a7fd995ac71d459ebe.min.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?digest=fade93df149f7c5fedb3ff897f799dc7d283b420" />
    <link rel="stylesheet" type="text/css" href="_static/dia.css" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  body[data-theme="dark"] {
    --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
  }
  @media (prefers-color-scheme: dark) {
    body:not([data-theme="light"]) {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
  }
</style></head>
  <body>
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    
<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round">
      <path stroke="none" d="M0 0h24v24H0z" />
      <line x1="4" y1="6" x2="20" y2="6" />
      <line x1="10" y1="12" x2="20" y2="12" />
      <line x1="6" y1="18" x2="20" y2="18" />
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">Hoffman2 Cluster Job Scheduling</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  
  <span class="sidebar-brand-text">Hoffman2 Cluster Job Scheduling</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="getting-started.html">Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="hello-world-job-script.html">Writing a “hello world” job script</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="appendix/ssh.html">Using secure client (ssh)</a></li>
</ul>

</div>
</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="hoffman2-cluster-job-scheduling-system">
<h1>Hoffman2 Cluster Job Scheduling System<a class="headerlink" href="#hoffman2-cluster-job-scheduling-system" title="Permalink to this headline">¶</a></h1>
<p>This technical note specifies the design requirements of the Hoffman2 Cluster’s job scheduling system.</p>
</section>
<section id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">¶</a></h1>
<p>Hoffman2 cluster is a major high performance computing infrastructure at UCLA, currently consisting more than 1300 computing nodes equipped with infiniband interconnect, high-speed storage system and advanced capabilities such as GPU computing and a large number of scientific software packages. Hoffman2 cluster’s operation follows a shared-cluster model, as defined in [1], in which most of the computing nodes are purchased by research groups using grant funding, while other compute nodes are funded by the university for general use. Users within a contributing research group can gain high priority access to their purchased nodes, and non-high priority access to other nodes. Currently, a high priority job is guaranteed to start within 24 hours after submission (more details are discussed later in this document), and can run as long as 14 days. General users not in any contributing research groups have (non-high priority) access to the university-funded nodes. A non-high priority job can run up to 24 hours. Pending available resources and the circumstances, it may be possible to make arrangement to reserve compute nodes for a finite period of time (e.g. for a class, a workshop or some special occasion); this normally requires lead time and is reviewed on a case by case basis.</p>
<p>This main body of this document focuses on explaining the scheduling policy and its implications and side effects; the details of how to specify the actual job parameters are available in the appendix. There are also a Hoffman2 cluster’s user guide [2] and Hoffman2 cluster’s user support web site [3]. In what follows, by scheduler software we refer to the Univa Grid Engine [4].</p>
<section id="job-scheduling-considerations">
<h2>Job Scheduling Considerations<a class="headerlink" href="#job-scheduling-considerations" title="Permalink to this headline">¶</a></h2>
<p>Hoffman2 cluster’s user base spans across multiple disciplines, from social sciences to engineering and medicine and more. Users from different domains tend to have significantly different computing patterns. Some users run a large number of independent sequential jobs, or IO intensive tasks, while others run massively parallel MPI-style jobs. Hoffman2 cluster’s job scheduler has a number of parameters for users to control how to allocate the needed computing resources for running jobs. Since Hoffman2 cluster has different generations of compute nodes (purchased over the years) and different memory sizes, among other things, a user may have to specify additional parameters beyond the default ones. This document summarizes the fundamental ideas behind how Hoffman2 cluster’s scheduler is set up and works, in the hope that it can help users to determine the optimal job parameters.</p>
<section id="high-priority-jobs">
<h3>High-priority jobs<a class="headerlink" href="#high-priority-jobs" title="Permalink to this headline">¶</a></h3>
<p>A high-priority job always runs on, and only on, a research group’s purchased nodes. Such a job normally starts within 24 hours, assuming the group’s jobs are not already occupying their purchased nodes. When a high-priority job is submitted to the scheduler queue and is detected by the system (by scanning the queue every 15 minutes), the scheduler starts to “drain” the group’s purchased nodes, which typically are already running other non-high priority jobs (e.g. from other research groups). As soon as enough (purchased) drained compute nodes, or CPU cores, are able to dispatch the incoming high priority job, the job starts, the draining stops, and the purchased nodes are open to accept other non-high priority jobs again, until the next high-priority-job scanning cycle. As long as there are still pending high-priority jobs, the draining will continue (i.e. to prevent other non-high priority jobs from starting on the purchased nodes). The implication of this is that, as long as the group has pending high priority jobs in the queue, only the first high priority job needs to wait for the draining; subsequent high priority jobs will run back to back, if not simultaneously, without the drain-wait time. Another implication of submitting a high priority job is that, while it is guaranteed to start within 24 hours (assuming no overuse), it can only start on the purchased nodes even if many other compute nodes (purchased by other research groups) are available; the wait time of high-priority jobs are not necessarily shorter.</p>
</section>
<section id="non-high-priority-jobs">
<h3>Non-high priority jobs<a class="headerlink" href="#non-high-priority-jobs" title="Permalink to this headline">¶</a></h3>
<p>A non-high priority job can run essentially anywhere on the cluster, except for a number of special-purposed reserved nodes. Currently, a non-high priority job has a time limit of 24 hours. While there is no guaranteed start time, it allows the scheduler to use its  algorithm to manage resources and to achieve high cluster utilization.  High utilization means that, overall, more jobs will be processed within the same time frame. Submitting non-high priority job is the recommended way of submitting jobs. For jobs requiring longer than the 24-hour time limit to complete, it is usually possible to break the computations into multiple less-than-24-hour segments, and run them piece by piece sequentially (also called “checkpoint” or “restart”). We note that Hoffman2 cluster’s 24-hour time limit is quite generous, considering the much shorter time limits per job in other NSF or DOE supercomputer centers.</p>
</section>
<section id="limit-on-the-number-of-jobs">
<h3>Limit on the number of jobs<a class="headerlink" href="#limit-on-the-number-of-jobs" title="Permalink to this headline">¶</a></h3>
<p>A user can have few hundreds of pending jobs into the queues; subsequent submission may be denied until the user’s number of pending jobs drops under the threshold again. The limit is dynamic; for example, when the cluster is less loaded, the limit is less restrictive. While this may seem an inconvenience, it is a safeguard so that the scheduler is not overwhelmed by the sheer number of pending jobs (recall that the Hoffman2 cluster has hundreds of active users). In practice, for users having to submit a large number of jobs, two approaches can be considered to circumvent the limit. One is to consider using “job array” (which requires a special syntax to submit jobs). The other is to pack multiple runs into one submission (e.g. by looping through multiple jobs sequentially in one submission).</p>
</section>
<section id="memory-limits">
<h3>Memory limits<a class="headerlink" href="#memory-limits" title="Permalink to this headline">¶</a></h3>
<p>Hoffman2 cluster imposes memory limits on jobs since each compute node has a finite amount of memory; a job consuming excessive amount of memory can affect the performance or even crash other jobs sharing the same node. It is the user’s responsibility to specify the appropriate amount of memory per job. If the user specifies too much memory, it may be difficult, or impossible, for the scheduler to find available compute node(s) to dispatch the job to. For example, when a job requests 64GB of memory to run, the scheduler cannot consider many of the computing nodes having 24GB or 48GB of total memory. If the specified memory is too low, and the peak memory usage exceeds it, the job may be killed by the scheduler. One tricky part of specifying memory size is that Hoffman2 cluster’s scheduler use the virtual memory size as the criterion to kill jobs, not the resident memory size which may be closer to the actual consumed memory amount. When the users cannot determine the needed memory size for a job, it is suggested to run the job in the exclusive mode, then use the the <code class="docutils literal notranslate"><span class="pre">qacct</span></code> command to inspect the job log to see the peak virtual memory size reached during run time.</p>
</section>
<section id="interactive-jobs">
<h3>Interactive jobs<a class="headerlink" href="#interactive-jobs" title="Permalink to this headline">¶</a></h3>
<p>An interactive job is initiated by the <code class="docutils literal notranslate"><span class="pre">qrsh</span></code> command (other than the <code class="docutils literal notranslate"><span class="pre">qsub</span></code> command to submit a batch job). Unlike batch jobs, which can wait in the queue for hours, users normally expect an interactive job to return with a few minutes. While a number of compute nodes are reserved exclusively for interactive use, their number of CPU cores and memory sizes are not infinite. There are times that interactive jobs cannot start immediately because, for example, the user requests an exceedingly large memory size or the number of CPU cores not immediately available at the moment of running the <code class="docutils literal notranslate"><span class="pre">qrsh</span></code> command.</p>
<p>It is possible to run high-priority interactive jobs on the user group’s purchased nodes, but they are subject to the same type of constraint mentioned above. It should be understood that the purchased nodes, not particularly reserved for interactive use, are most likely already running other batch jobs; the interactive job might not be able to start immediately.</p>
</section>
<section id="specifying-special-hardware">
<h3>Specifying special hardware<a class="headerlink" href="#specifying-special-hardware" title="Permalink to this headline">¶</a></h3>
<p>A diversity of different CPU architectures and GPUs are available on Hoffman2 cluster. When a job does not specify special hardware features, it is dispatched to an (or some) arbitrary compute node(s). When a job specifies additional hardware features, it will be dispatched only to compute nodes having those features. Of course, when contradicting parameters are specified, the job is stuck in the queue (i.e. pending forever for no matching hardware). For example, Hoffman2 cluster has both Intel- and AMD-based compute nodes. To force a job to run on the Intel CPUs, the user can specify <code class="docutils literal notranslate"><span class="pre">-l</span> <span class="pre">arch=intel*</span></code>. A number of special high-memory compute nodes are available (to the users having access to them) using this approach by viewing the high memory as a hardware feature. Specifying certain hardware features give the user some control where to run the job. At the same time, when the choices become too strict, the wait time may significantly increase because the number of compute nodes matching the criteria may be small, if not zero.</p>
</section>
</section>
<section id="job-submission-in-practice">
<h2>Job Submission in Practice<a class="headerlink" href="#job-submission-in-practice" title="Permalink to this headline">¶</a></h2>
<p>The two most important parameters of submitting a job, batch or interactive, are the time limit (specified by <code class="docutils literal notranslate"><span class="pre">h_rt</span></code>) and memory size (specified by <code class="docutils literal notranslate"><span class="pre">h_data</span></code>). For multithreaded (shared memory) or MPI (distributed memory) parallel jobs, the number of CPU cores also are required (specified by <code class="docutils literal notranslate"><span class="pre">-pe</span></code>). The job parameters can be passed to the job scheduler either from the command line or written in the job script file. For example, to request  8 hours of computing time and 4GB of memory for a sequential job using the command line approach, the user would issue the command:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>qsub -N $job_name -l h_rt=8:00:00,h_data=4G -cwd $job_script
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">$job_script</span></code> is replaced with the name of the shell script that drives the computations (e.g. <code class="docutils literal notranslate"><span class="pre">foo.sh</span></code>). The <code class="docutils literal notranslate"><span class="pre">-N</span></code> option, which specifies the job name, is optional but is helpful to label the jobs when the user has multiple of them (e.g. <code class="docutils literal notranslate"><span class="pre">foo1</span></code>, <code class="docutils literal notranslate"><span class="pre">foo2</span></code>, etc.).  It should be noted that the runtime environment of the job may be different from the interactive shell the user has (e.g. in the interactive terminal used to issue the <code class="docutils literal notranslate"><span class="pre">qsub</span></code> command). This is related to how Linux operating system initialize an interactive and non-interactive session. In addition, when a job starts, it starts from the top level home directory of the user (i.e. the path defined in the environment variable <code class="docutils literal notranslate"><span class="pre">$HOME</span></code>), which may be different from the directory where the job is intended to run (e.g. containing data files and scripts for the run). This is easily addressed by the <code class="docutils literal notranslate"><span class="pre">-cwd</span></code> option, which means “running from the directory where the job is submitted.”</p>
<p>To write all of the job parameters into the job script, see the examples Appendix. The general syntax is that the job parameter lines are prefixed by <code class="docutils literal notranslate"><span class="pre">#$</span></code>, which is viewed as a comment in the Linux shell, but is recognized by the job scheduler as a job parameter. For example, the equivalent job script corresponding to the example above is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#$ -N job_name</span>
<span class="c1">#$ -l h_rt=8:00:00,h_data=4G</span>
<span class="c1">#$ -cwd</span>
<span class="o">...</span>
</pre></div>
</div>
<p>The order of the job parameters does not matter. When duplicate items appear in the same script, only the last one is effective. It is permissible to split the parameters of <code class="docutils literal notranslate"><span class="pre">-l</span></code> into multiple lines in a job script, i.e.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#$ -N job_name</span>
<span class="c1">#$ -l h_rt=8:00:00</span>
<span class="c1">#$ -l h_data=4G</span>
<span class="c1">#$ -cwd</span>
<span class="o">...</span>
</pre></div>
</div>
<p>For parallel jobs, additional parameters are required but can be specified in the same manner. See the Appendix for full examples.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>[1] Hoffman2 cluster scheduling policy. <a class="reference external" href="https://idre.ucla.edu/resources/hpc/hoffman2-cluster"><code class="docutils literal notranslate"><span class="pre">https://idre.ucla.edu/resources/hpc/hoffman2-cluster</span></code></a></p></li>
<li><p>[2] Hoffman2 user’s guide. <a class="reference external" href="https://www.hoffman2.idre.ucla.edu/"><code class="docutils literal notranslate"><span class="pre">https://www.hoffman2.idre.ucla.edu/</span></code></a></p></li>
<li><p>[3] Hoffman2 cluster user support. <a class="reference external" href="https://support.idre.ucla.edu/helpdesk/"><code class="docutils literal notranslate"><span class="pre">https://support.idre.ucla.edu/helpdesk/</span></code></a></p></li>
<li><p>[4] Univa Grid Engine. <a class="reference external" href="http://www.univa.com/products/"><code class="docutils literal notranslate"><span class="pre">http://www.univa.com/products/</span></code></a></p></li>
</ul>
</section>
<section id="appendix">
<h2>Appendix<a class="headerlink" href="#appendix" title="Permalink to this headline">¶</a></h2>
<section id="job-script-examples">
<h3>Job script examples<a class="headerlink" href="#job-script-examples" title="Permalink to this headline">¶</a></h3>
<p>Some examples are included below for completeness of this document, to show what a simple job script would look like. More examples are available at <a class="reference external" href="https://github.com/ucla-oarc-cs/sge-job-scripts">this github repository</a>. In each example, save the script as a file, e.g. <code class="docutils literal notranslate"><span class="pre">foo.sh</span></code> then submit the job by the command <code class="docutils literal notranslate"><span class="pre">qsub</span> <span class="pre">foo.sh</span></code>.</p>
<section id="sequential-job">
<h4>Sequential job<a class="headerlink" href="#sequential-job" title="Permalink to this headline">¶</a></h4>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#$ -l h_rt=01:00:00</span>
<span class="c1">#$ -l h_data=2G</span>
<span class="c1">#$ -N job_name</span>
<span class="c1">#$ -cwd</span>
<span class="c1">#$ -o stdout.$JOB_ID</span>
<span class="c1">#$ -e stderr.$JOB_ID</span>

<span class="c1"># put your commands below, e.g.</span>
date
hostname
</pre></div>
</div>
</section>
<section id="shared-memory-multithreaded-job">
<h4>Shared-memory (multithreaded) job<a class="headerlink" href="#shared-memory-multithreaded-job" title="Permalink to this headline">¶</a></h4>
<p>This type of jobs uses multiple CPU cores from the <em>same</em> compute node. The product of <code class="docutils literal notranslate"><span class="pre">h_data</span></code> and <code class="docutils literal notranslate"><span class="pre">-pe</span></code> has to be no more than a compute node’s physical memory size. If the product is too large, the job may never start. Use the command <code class="docutils literal notranslate"><span class="pre">qhost</span></code> to inspect the available memory size of the compute nodes.
An otherwise non-parallel program does <em>not</em> automatically become parallel by submitting it as a parallel job.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#$ -l h_rt=01:00:00</span>
<span class="c1">#$ -l h_data=2G,exclusive</span>
<span class="c1">#$ -N job_name</span>
<span class="c1">#$ -cwd</span>
<span class="c1">#$ -o stdout.$JOB_ID</span>
<span class="c1">#$ -e stderr.$JOB_ID</span>
<span class="c1">#$ -pe shared 8</span>

<span class="c1"># put your commands below, e.g.</span>
date
hostname
</pre></div>
</div>
</section>
<section id="mpi-distributed-memory-parallel-job">
<h4>MPI distributed-memory parallel job<a class="headerlink" href="#mpi-distributed-memory-parallel-job" title="Permalink to this headline">¶</a></h4>
<p>This type of jobs uses multiple CPU cores across multiple compute nodes. The inter-process communication typically uses MPI (Message Passing Interface) or something equivalent. The program (application) must be capable of performing such inter-process communication. An otherwise non-parallel program does <em>not</em> automatically become parallel by submitting it as a parallel job.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#$ -l h_rt=01:00:00</span>
<span class="c1">#$ -l h_data=2G</span>
<span class="c1">#$ -N job_name</span>
<span class="c1">#$ -cwd</span>
<span class="c1">#$ -o stdout.$JOB_ID</span>
<span class="c1">#$ -e stderr.$JOB_ID</span>
<span class="c1">#$ -pe dc* 8</span>

<span class="c1"># put your commands below, e.g.</span>
<span class="nb">source</span> /u/local/Modules/default/init/modules.sh
module load intel/18.0.3
date
which mpirun
mpirun -n <span class="nv">$NSLOTS</span> hostname
</pre></div>
</div>
</section>
</section>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>

        <div class="related-information">
            Last updated on 2022-07-16. |
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Hoffman2 Cluster Job Scheduling System</a></li>
<li><a class="reference internal" href="#overview">Overview</a><ul>
<li><a class="reference internal" href="#job-scheduling-considerations">Job Scheduling Considerations</a><ul>
<li><a class="reference internal" href="#high-priority-jobs">High-priority jobs</a></li>
<li><a class="reference internal" href="#non-high-priority-jobs">Non-high priority jobs</a></li>
<li><a class="reference internal" href="#limit-on-the-number-of-jobs">Limit on the number of jobs</a></li>
<li><a class="reference internal" href="#memory-limits">Memory limits</a></li>
<li><a class="reference internal" href="#interactive-jobs">Interactive jobs</a></li>
<li><a class="reference internal" href="#specifying-special-hardware">Specifying special hardware</a></li>
</ul>
</li>
<li><a class="reference internal" href="#job-submission-in-practice">Job Submission in Practice</a></li>
<li><a class="reference internal" href="#references">References</a></li>
<li><a class="reference internal" href="#appendix">Appendix</a><ul>
<li><a class="reference internal" href="#job-script-examples">Job script examples</a><ul>
<li><a class="reference internal" href="#sequential-job">Sequential job</a></li>
<li><a class="reference internal" href="#shared-memory-multithreaded-job">Shared-memory (multithreaded) job</a></li>
<li><a class="reference internal" href="#mpi-distributed-memory-parallel-job">MPI distributed-memory parallel job</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/scripts/furo.js"></script>
    <script src="_static/design-tabs.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    </body>
</html>